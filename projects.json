[
  {
    "id": "group-testing",
    "title": "Capstone: Advanced Group Testing for Community Infection Control",
    "duration": "June 2024 â€“ June 2025",
    "tech": "Python, Graph Theory, Simulation",
    "description": "This was a year-long research-driven capstone project focused on designing and evaluating advanced testing strategies for large-scale community infection control. The goal was to reduce the number of diagnostic tests required while maintaining high accuracy in detecting infections.\n\nUsing Python as the primary language, I built a simulation environment that modeled infection spread across populations of up to 10,000 nodes. The simulation incorporated three well-established graph models: ErdÅ‘sâ€“RÃ©nyi (random graphs), BarabÃ¡siâ€“Albert (scale-free networks), and Wattsâ€“Strogatz (small-world networks), allowing exploration of how different social connectivity patterns affect testing outcomes.\n\nI implemented and compared four testing strategies:\n- Naive individual testing\n- Dorfman group testing (classic two-stage pooling)\n- Two-Stage Adaptive Testing\n- Graph-Constrained Adaptive Group Testing (GCAGT)\n\nThe project evaluated strategies using metrics such as total test count, detection accuracy, and false positive/negative rates, under varying infection prevalence levels. Results showed that GCAGT reduced test counts by up to 70% in clustered populations compared to naive testing, highlighting the power of graph-aware adaptive approaches.\n\nTech stack & tools: Python 3.12, NumPy, Pandas, NetworkX, Matplotlib, Seaborn, Google Colab/Jupyter, Git & Bitbucket, Confluence.\n\nThis project provided practical insights into scalable testing under limited-resource conditions and demonstrated how computational models and graph theory can inform public health decision-making.",
    "image": "group-testing.png"
  },
  {
    "id": "attendance",
    "title": "Face Detection-Based Attendance System",
    "tech": "Python, OpenCV, Flask",
    "description": "I developed a real-time face detection and recognition-based attendance system aimed at automating the process of recording attendance in classrooms and workplaces.\n\nThe system was built using Python and leverages computer vision libraries such as OpenCV for face detection and Haar cascades for feature extraction. For robust recognition, the pipeline integrated pre-trained deep learning models capable of generating face embeddings and comparing them against a stored dataset of registered users. This approach achieved over 95% accuracy under varying conditions such as lighting changes, camera angles, and partial occlusions.\n\nThe backend was implemented using Flask, which allowed seamless communication between the recognition module and a lightweight web server. Each time a student or employeeâ€™s face was successfully recognized, the system automatically logged the attendance into a structured database, eliminating the need for manual roll calls. The database component was designed with SQLite for easy deployment, but the system architecture also supports integration with larger databases such as MySQL for scaling to enterprise use.\n\nA simple web-based interface was created using HTML, CSS, and Bootstrap to provide administrators with a dashboard where attendance records could be viewed, searched, and exported. The system was designed to be fast and efficient, capable of operating in real time on commodity hardware using only a standard webcam.\n\nTech stack & tools: Python 3.x, OpenCV, Dlib/Face Recognition library, Flask, SQLite/MySQL, NumPy, Pandas, HTML/CSS/Bootstrap.\n\nThis project demonstrated how computer vision, deep learning, and lightweight backend technologies can be combined to solve a real-world problem. It reduced human error, streamlined the attendance process, and showcased practical applications of AI in education and workforce management.",
    "image": "attendance-system.png"
  },
  {
    "id": "fruits",
    "title": "Fruit Recognition System",
    "tech": "Python, TensorFlow, Image Processing",
    "description": "This project focused on developing an image classification pipeline capable of accurately identifying different fruit categories. The primary goal was to demonstrate the application of deep learning techniques in computer vision tasks related to agriculture, retail, and automated recognition systems.\n\nThe dataset consisted of more than 2,200 labeled images spanning 22 fruit categories. To ensure robustness and generalization, the images were preprocessed using techniques such as resizing, normalization, and data augmentation. Augmentation operations included rotations, flips, and brightness adjustments, which helped the model learn invariance to common variations in real-world data.\n\nA Convolutional Neural Network (CNN) was designed and trained using TensorFlow/Keras. The architecture was optimized through iterative experimentation with filter sizes, activation functions, and dropout layers to prevent overfitting. The final model achieved an impressive 98% classification accuracy, with a false positive rate of less than 2%. Performance evaluation was carried out using confusion matrices, precision, recall, and F1-scores to gain a comprehensive understanding of the modelâ€™s strengths and weaknesses.\n\nFor visualization, Matplotlib was used to display training and validation accuracy/loss curves, as well as prediction confidence scores for sample test images. This provided insights into the learning dynamics and demonstrated the systemâ€™s decision-making process.\n\nTech stack & tools: Python 3.x, TensorFlow/Keras, NumPy, Pandas, Matplotlib, Seaborn, Scikit-learn, Google Colab.\n\nThis project showcased the potential of deep learning in building practical computer vision systems. It has applications in smart checkout counters, automated food inventory systems, and agricultural sorting, where accurate and fast classification of produce is essential.",
    "image": "fruit-recognition-system.png"
  },
  {
    "id": "cyber-chatbot",
    "title": "Interactive Cybersecurity Chatbot",
    "tech": "Java",
    "description": "I created an educational chatbot designed to simulate phishing and cybersecurity awareness scenarios, helping users recognize and respond to common social engineering threats in a safe environment.\n\nThe chatbot was developed in Java and built around a modular design that separates scenario content from program logic. More than 10 phishing scenarios were authored in JSON format, covering common attack vectors such as suspicious emails, fake login prompts, and malicious links. These scenarios were parsed at runtime by the chatbot, allowing the system to dynamically load question flows, branching responses, and feedback messages.\n\nWhen interacting with the chatbot, users were presented with simulated messages or situations and had to make decisions, such as whether to click a link, enter credentials, or report the suspicious activity. Based on their choices, the chatbot provided immediate feedback, reinforcing secure behavior or highlighting mistakes. This interactive approach turned passive awareness training into an engaging and practical exercise.\n\nThe project emphasized modularity and scalability. New scenarios could be added simply by editing JSON files, without modifying the Java codebase, making the system adaptable to evolving cybersecurity threats. Unit testing was performed using JUnit to validate the correctness of the chatbotâ€™s response flows and ensure robust handling of user input.\n\nTech stack & tools: Java (JDK 17), JSON for scenario configuration, Java Swing/Console for interaction, JUnit for testing, Git for version control.\n\nThis project demonstrated how software engineering principles can be applied to cybersecurity education. It blended backend programming with JSON-driven content management to create a reusable and extendable tool for training. By simulating realistic phishing scenarios, the chatbot helped improve awareness and reduce vulnerability to common cyberattacks.",
    "image": "cyber-chatbot.png"
  },
  {
    "id": "tasky",
    "title": "Tasky - To-Do List",
    "tech": "React, Vite, localStorage, CSS",
    "image": "tasky.png",
    "description": "Tasky is a simple and clean to-do list application built with React and Vite. It provides an intuitive interface for managing daily tasks, while ensuring persistence using the browserâ€™s localStorage API.\n\nThe app allows users to add new tasks, mark them as complete, and delete tasks they no longer need. Unlike many lightweight task apps, Tasky saves all tasks directly in localStorage, which means they remain intact even after refreshing the page or closing the browser. This makes it a practical solution for quick and reliable task tracking.\n\nâœ¨ Features:\nâ€¢ Add new tasks\nâ€¢ Mark tasks as complete\nâ€¢ Delete tasks\nâ€¢ Tasks persist via localStorage\nâ€¢ Fully responsive layout for desktop and mobile\n\nðŸš€ Tech stack:\nReact â€“ Frontend framework\nVite â€“ Build tool and dev server\nlocalStorage â€“ Task persistence\nCSS â€“ Styling and responsive layout\n\nTasky demonstrates how a minimal React project can be turned into a functional productivity tool by leveraging local browser storage. It also highlights the use of Vite for a fast development environment and optimized builds.",
    "demoLink": "https://tasky-to-do-list.vercel.app/",
    "githubLink": "https://github.com/shrikantbk06/tasky-to-do-list"
 }

]
